{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data (F & L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Successfully Loaded\n",
      "Shape of Data: (50, 11)\n",
      "Header File,Magnitude_Vel,Hor_Vel,Vert_Vel,Magnitude_Acc,Hor_Acc,Vert_Acc,Magnitude_Jerk,Hor_Jerk,Vert_Jerk,NCV\n",
      "Frist 5 rows:\n",
      "[[           nan 2.01029732e-01 1.38796988e-01 1.14737580e-01\n",
      "  7.47646391e-04 5.16730740e-04 4.49483436e-04 7.89421502e-06\n",
      "  5.62574433e-06 4.42658017e-06 1.43333333e+02]\n",
      " [           nan 7.13142044e-02 4.72859718e-02 4.38039334e-02\n",
      "  3.38042403e-04 2.18903376e-04 2.04876171e-04 5.46746396e-06\n",
      "  3.50740064e-06 3.32671043e-06 3.17166667e+02]\n",
      " [           nan 6.82116936e-02 4.28016428e-02 4.34729879e-02\n",
      "  2.70040861e-04 1.74852679e-04 1.63477892e-04 4.12696616e-06\n",
      "  2.70512682e-06 2.56366607e-06 2.40000000e+02]\n",
      " [           nan 5.95352310e-02 3.77155830e-02 3.85859280e-02\n",
      "  1.96452657e-04 1.19628639e-04 1.19973122e-04 3.56274936e-06\n",
      "  2.21597901e-06 2.21626927e-06 3.15857143e+02]\n",
      " [           nan 7.60646321e-02 4.97343270e-02 4.84274346e-02\n",
      "  2.05469405e-04 1.30649210e-04 1.22180597e-04 3.35696071e-06\n",
      "  2.15458420e-06 2.09343702e-06 2.10400000e+02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pd_features_file = r'C:\\Users\\priya\\OneDrive\\Desktop\\Notes\\Media Programming\\Final Project_PD Detection\\pd_features.csv'\n",
    "\n",
    "def load_features(pd_features_file):\n",
    "    with open(pd_features_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    # header = lines[0]\n",
    "    header = lines[0].strip()\n",
    "    #data = np.genfromtxt(lines[1:], delimiter= '', dtype=float)\n",
    "    data = np.genfromtxt(lines[1:], delimiter= ',', dtype=float)\n",
    "    return data, header\n",
    "\n",
    "data, header = load_features(pd_features_file)\n",
    "\n",
    "print(\"Features Successfully Loaded\")\n",
    "print(\"Shape of Data:\", data.shape)\n",
    "print(\"Header\", header)\n",
    "print(\"Frist 5 rows:\")\n",
    "print(data[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess features\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "print(scaler)\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mfeatures\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, labels\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17, 9)\n",
      "X_test shape: (8, 9)\n",
      "y_train shape: (17,)\n",
      "y_test shape: (8,)\n",
      "Training class distribution: [ 0 17]\n",
      "Testing class distribution: [0 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Stratified splitting to maintain class balance\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_idx, test_idx in splitter.split(features, labels):\n",
    "    X_train, X_test = features[train_idx], features[test_idx]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Verify class distribution\n",
    "print(\"Training class distribution:\", np.bincount(y_train))\n",
    "print(\"Testing class distribution:\", np.bincount(y_test))\n",
    "\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=7)\n",
    "# for train_idx, test_idx in splitter.split(features, labels):\n",
    "#     X_train, X_test = features[train_idx], features[test_idx]\n",
    "#     y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "# print(\"Training class distribution:\", np.bincount(y_train))\n",
    "# print(\"Testing class distribution:\", np.bincount(y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training class distribution:\", np.bincount(y_train))\n",
    "# print(\"Testing class distribution:\", np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Sample X_train:\", X_train[:5])\n",
    "# print(\"Sample y_train:\", y_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[276], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m \u001b[43mplot\u001b[49m(f\u001b[38;5;241m=\u001b[39mparkinson_file_list[\u001b[38;5;241m35\u001b[39m],  plot_func\u001b[38;5;241m=\u001b[39msns\u001b[38;5;241m.\u001b[39mbarplot, t_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPressure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": [
    "plot(f=parkinson_file_list[35],  plot_func=sns.barplot, t_id=0, x='Timestamp', y='Pressure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split DaTA (Test and Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train-test split\n",
    "# np.random.seed(42)\n",
    "# pos_indices = np.where(labels == 1)[0]\n",
    "# neg_indices = np.where(labels == 0)[0]\n",
    "\n",
    "# np.random.shuffle(pos_indices)\n",
    "# np.random.shuffle(neg_indices)\n",
    "\n",
    "# train_pos = pos_indices[:-5]\n",
    "# test_pos = pos_indices[-5:]\n",
    "# train_neg = neg_indices[:-5]\n",
    "# test_neg = neg_indices[-5:]\n",
    "\n",
    "# train_indices = np.concatenate([train_pos, train_neg])\n",
    "# test_indices = np.concatenate([test_pos, test_neg])\n",
    "\n",
    "# X_train = features[train_indices]\n",
    "# y_train = labels[train_indices]\n",
    "# X_test = features[test_indices]\n",
    "# y_test = labels[test_indices]\n",
    "\n",
    "# print(\"Training set shape:\", X_train.shape)\n",
    "# print(\"Testing set shape:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics function\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision * 100:.2f}%\")\n",
    "    print(f\"Recall: {recall * 100:.2f}%\")\n",
    "    print(f\"F1 Score: {f1 * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting the dataset into positive and negative cases\n",
    "# pos_indices = np.where(labels == 1)[0]\n",
    "# neg_indices = np.where(labels == 0)[0]\n",
    "\n",
    "# # Shuffle indices to ensure randomness\n",
    "# np.random.shuffle(pos_indices)\n",
    "# np.random.shuffle(neg_indices)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# train_pos = pos_indices[:-5]\n",
    "# test_pos = pos_indices[-5:]\n",
    "# train_neg = neg_indices[:-5]\n",
    "# test_neg = neg_indices[-5:]\n",
    "\n",
    "# # Create training and testing datasets\n",
    "# train_indices = np.concatenate([train_pos, train_neg])\n",
    "# test_indices = np.concatenate([test_pos, test_neg])\n",
    "\n",
    "# X_train = features[train_indices]\n",
    "# y_train = labels[train_indices]\n",
    "# X_test = features[test_indices]\n",
    "# y_test = labels[test_indices]\n",
    "\n",
    "# print(\"Training set shape:\", X_train.shape)\n",
    "# print(\"Testing set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction,actual):\n",
    "    correct = 0\n",
    "    not_correct = 0\n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i] == actual[i]:\n",
    "            correct+=1\n",
    "        else:\n",
    "            not_correct+=1\n",
    "    return (correct*100)/(correct+not_correct)\n",
    "\n",
    "\n",
    "def metrics(prediction,actual):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i] == actual[i] and actual[i]==1:\n",
    "            tp+=1\n",
    "        if prediction[i] == actual[i] and actual[i]==0:\n",
    "            tn+=1\n",
    "        if prediction[i] != actual[i] and actual[i]==0:\n",
    "            fp+=1\n",
    "        if prediction[i] != actual[i] and actual[i]==1:\n",
    "            fn+=1\n",
    "    metrics = {'Precision':(tp/(tp+fp+tn+fn)),'Recall':(tp/(tp+fn)),'F1':(2*(tp/(tp+fp+tn+fn))*(tp/(tp+fn)))/((tp/(tp+fp+tn+fn))+(tp/(tp+fn)))}\n",
    "    return (metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "def train_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    false_positive_rate = calculate_false_positive_rate(y_test, y_pred)\n",
    "    print(f\"Logistic Regression Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Logistic Regression False Positive Rate: {false_positive_rate * 100:.2f}%\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "def train_random_forest(X_train, y_train, X_test, y_test):\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    false_positive_rate = calculate_false_positive_rate(y_test, y_pred)\n",
    "    print(f\"Random Forest Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Random Forest False Positive Rate: {false_positive_rate * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train K-Nearest Neighbors\n",
    "def train_knn(X_train, y_train, X_test, y_test):\n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    false_positive_rate = calculate_false_positive_rate(y_test, y_pred)\n",
    "    print(f\"KNN Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"KNN False Positive Rate: {false_positive_rate * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Support Vector Machine\n",
    "def train_svm(X_train, y_train, X_test, y_test):\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    false_positive_rate = calculate_false_positive_rate(y_test, y_pred)\n",
    "    print(f\"SVM Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"SVM False Positive Rate: {false_positive_rate * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "def train_xgboost(X_train, y_train, X_test, y_test):\n",
    "    clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    false_positive_rate = calculate_false_positive_rate(y_test, y_pred)\n",
    "    print(f\"XGBoost Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"XGBoost False Positive Rate: {false_positive_rate * 100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[215], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train and evaluate models separately\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_logistic_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m train_random_forest(X_train, y_train, X_test, y_test)\n\u001b[0;32m      4\u001b[0m train_knn(X_train, y_train, X_test, y_test)\n",
      "Cell \u001b[1;32mIn[210], line 4\u001b[0m, in \u001b[0;36mtrain_logistic_regression\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_logistic_regression\u001b[39m(X_train, y_train, X_test, y_test):\n\u001b[0;32m      3\u001b[0m     clf \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:1301\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1299\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1303\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1305\u001b[0m     )\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1308\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.int64(1)"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models separately\n",
    "train_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "train_random_forest(X_train, y_train, X_test, y_test)\n",
    "train_knn(X_train, y_train, X_test, y_test)\n",
    "train_svm(X_train, y_train, X_test, y_test)\n",
    "train_xgboost(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Classifier training and evaluation\n",
    "# classifiers = {\n",
    "#     \"Logistic Regression\": LogisticRegression(),\n",
    "#     \"Random Forest\": RandomForestClassifier(),\n",
    "#     \"Support Vector Machine\": SVC(),\n",
    "#     \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "#     \"XGBoost\": XGBClassifier(),\n",
    "#     \"Decision Tree\": DecisionTreeClassifier(),\n",
    "# }\n",
    "\n",
    "# for name, clf in classifiers.items():\n",
    "#     print(f\"Training {name}...\")\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     evaluate_model(y_test, y_pred, name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
